@preconcurrency import AVFoundation
import UIKit
import Combine
import CoreMedia

/// –°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∫–∞–º–µ—Ä–æ–π
@MainActor
class CameraService: NSObject, ObservableObject {
    
    // MARK: - Errors
    
    enum CameraError: Error, LocalizedError {
        case noCameraAvailable
        case cannotAddInput
        case cannotAddOutput
        case lensNotAvailable(LensPreset)
        
        nonisolated var errorDescription: String? {
            switch self {
            case .noCameraAvailable: return "–ö–∞–º–µ—Ä–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"
            case .cannotAddInput: return "–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å –≤—Ö–æ–¥ –∫–∞–º–µ—Ä—ã"
            case .cannotAddOutput: return "–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å –≤—ã—Ö–æ–¥ —Ñ–æ—Ç–æ"
            case .lensNotAvailable(let lens):
                // Access displayLabel in a non-isolated way
                let label: String
                switch lens {
                case .ultraWide: label = "0.5"
                case .wide: label = "1x"
                case .telephoto: label = "3x"
                }
                return "–õ–∏–Ω–∑–∞ \(label) –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"
            }
        }
    }
    
    // MARK: - Published Properties
    
    @Published var isSessionRunning = false
    @Published var capturedPhoto: PhotoCapture?
    @Published private(set) var currentLens: LensPreset = .wide
    @Published private(set) var availableLenses: [LensPreset] = []
    
    // MARK: - Private Properties
    
    private let captureSession = AVCaptureSession()
    private let photoOutput = AVCapturePhotoOutput()
    private var videoDeviceInput: AVCaptureDeviceInput?
    private var currentCamera: AVCaptureDevice?
    private var photoCaptureDelegate: PhotoCaptureDelegate?
    
    /// –û—á–µ—Ä–µ–¥—å –¥–ª—è –æ–ø–µ—Ä–∞—Ü–∏–π —Å —Å–µ—Å—Å–∏–µ–π (–Ω–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç main thread)
    private let sessionQueue = DispatchQueue(label: "com.lutcamera.session", qos: .userInitiated)
    
    private lazy var previewLayerInstance: AVCaptureVideoPreviewLayer = {
        let layer = AVCaptureVideoPreviewLayer(session: captureSession)
        layer.videoGravity = .resizeAspectFill
        return layer
    }()
    
    var previewLayer: AVCaptureVideoPreviewLayer {
        previewLayerInstance
    }

    // MARK: - Setup
    
    func setupSession() async throws {
        // –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ª–∏–Ω–∑—ã –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ
        detectAvailableLenses()
        
        captureSession.beginConfiguration()
        captureSession.sessionPreset = .photo
        
        // –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—Ç–∞—Ä—Ç—É–µ–º —Å wide (1x)
        guard let camera = getDevice(for: .wide) else {
            throw CameraError.noCameraAvailable
        }
        
        try configureCamera(camera)
        currentCamera = camera
        currentLens = .wide
        
        let input = try AVCaptureDeviceInput(device: camera)
        guard captureSession.canAddInput(input) else { throw CameraError.cannotAddInput }
        captureSession.addInput(input)
        videoDeviceInput = input
        
        guard captureSession.canAddOutput(photoOutput) else { throw CameraError.cannotAddOutput }
        captureSession.addOutput(photoOutput)
        
        // –í–∫–ª—é—á–∞–µ–º –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Å—ä–µ–º–∫–∏ –≤ 48 –ú–ü
        configurePhotoOutput(for: camera)
        
        captureSession.commitConfiguration()
    }
    
    /// –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞–∫–∏–µ –ª–∏–Ω–∑—ã –¥–æ—Å—Ç—É–ø–Ω—ã –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ
    private func detectAvailableLenses() {
        let discoverySession = AVCaptureDevice.DiscoverySession(
            deviceTypes: [.builtInUltraWideCamera, .builtInWideAngleCamera, .builtInTelephotoCamera],
            mediaType: .video,
            position: .back
        )
        
        var lenses: [LensPreset] = []
        for device in discoverySession.devices {
            switch device.deviceType {
            case .builtInUltraWideCamera:
                lenses.append(.ultraWide)
            case .builtInWideAngleCamera:
                lenses.append(.wide)
            case .builtInTelephotoCamera:
                lenses.append(.telephoto)
            default:
                break
            }
        }
        
        // –°–æ—Ä—Ç–∏—Ä—É–µ–º –≤ –ø–æ—Ä—è–¥–∫–µ 0.5x, 1x, 3x
        availableLenses = LensPreset.allCases.filter { lenses.contains($0) }
        print("üì∑ –î–æ—Å—Ç—É–ø–Ω—ã–µ –ª–∏–Ω–∑—ã: \(availableLenses.map { $0.displayLabel })")
    }

    /// –ü–æ–ª—É—á–∞–µ—Ç —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –ª–∏–Ω–∑—ã
    private func getDevice(for lens: LensPreset, position: AVCaptureDevice.Position = .back) -> AVCaptureDevice? {
        AVCaptureDevice.default(lens.deviceType, for: .video, position: position)
    }
    
    /// –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –∫–∞–º–µ—Ä—É (–∞–≤—Ç–æ—Ñ–æ–∫—É—Å –∏ —Ç.–¥.)
    private func configureCamera(_ camera: AVCaptureDevice) throws {
        try camera.lockForConfiguration()
        if camera.isFocusModeSupported(.continuousAutoFocus) {
            camera.focusMode = .continuousAutoFocus
        }
        if camera.isExposureModeSupported(.continuousAutoExposure) {
            camera.exposureMode = .continuousAutoExposure
        }
        camera.unlockForConfiguration()
    }
    
    /// –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç photoOutput –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è
    private func configurePhotoOutput(for camera: AVCaptureDevice) {
        photoOutput.maxPhotoQualityPrioritization = .quality
        
        if #available(iOS 16.0, *) {
            if let maxDimension = camera.activeFormat.supportedMaxPhotoDimensions.max(by: {
                $0.width * $0.height < $1.width * $1.height
            }) {
                photoOutput.maxPhotoDimensions = maxDimension
            }
        } else {
            photoOutput.isHighResolutionCaptureEnabled = true
        }
    }
    
    // MARK: - Session Controls
    
    func startSession() {
        Task {
            await startSessionInternal()
        }
    }
    
    func stopSession() {
        Task {
            await stopSessionInternal()
        }
    }
    
    private func startSessionInternal() async {
        guard !captureSession.isRunning else { return }
        
        // Capture the session reference on MainActor before going to background
        let session = captureSession
        
        await withCheckedContinuation { continuation in
            sessionQueue.async {
                session.startRunning()
                
                Task { @MainActor in
                    self.isSessionRunning = session.isRunning
                    continuation.resume()
                }
            }
        }
    }
    
    private func stopSessionInternal() async {
        guard captureSession.isRunning else { return }
        
        // Capture the session reference on MainActor before going to background
        let session = captureSession
        
        await withCheckedContinuation { continuation in
            sessionQueue.async {
                session.stopRunning()
                
                Task { @MainActor in
                    self.isSessionRunning = false
                    continuation.resume()
                }
            }
        }
    }

    // MARK: - Lens Switching (–ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø)
    
    /// –ü–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç —Ñ–∏–∑–∏—á–µ—Å–∫—É—é –ª–∏–Ω–∑—É –∫–∞–º–µ—Ä—ã
    /// - Parameter lens: –¶–µ–ª–µ–≤–æ–π –ø—Ä–µ—Å–µ—Ç –ª–∏–Ω–∑—ã
    func switchLens(to lens: LensPreset) async throws {
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –ª–∏–Ω–∑—ã
        guard availableLenses.contains(lens) else {
            throw CameraError.lensNotAvailable(lens)
        }
        
        // –ï—Å–ª–∏ —É–∂–µ –Ω–∞ —ç—Ç–æ–π –ª–∏–Ω–∑–µ ‚Äî –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º
        guard lens != currentLens else { return }
        
        // –ü–æ–ª—É—á–∞–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –Ω–æ–≤–æ–π –ª–∏–Ω–∑—ã
        guard let newCamera = getDevice(for: lens) else {
            throw CameraError.lensNotAvailable(lens)
        }
        
        // –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π input
        let newInput = try AVCaptureDeviceInput(device: newCamera)
        
        // Swap input –≤ —Å–µ—Å—Å–∏–∏
        captureSession.beginConfiguration()
        
        // –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π input
        if let oldInput = videoDeviceInput {
            captureSession.removeInput(oldInput)
        }
        
        // –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π input
        guard captureSession.canAddInput(newInput) else {
            // Rollback ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç–∞—Ä—ã–π input
            if let oldInput = videoDeviceInput {
                captureSession.addInput(oldInput)
            }
            captureSession.commitConfiguration()
            throw CameraError.cannotAddInput
        }
        
        captureSession.addInput(newInput)
        videoDeviceInput = newInput
        currentCamera = newCamera
        
        // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫–∞–º–µ—Ä—É
        try? configureCamera(newCamera)
        
        // –ü–µ—Ä–µ–Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º output –¥–ª—è –Ω–æ–≤–æ–≥–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ (–≤–∞–∂–Ω–æ –¥–ª—è 48MP)
        configurePhotoOutput(for: newCamera)
        
        captureSession.commitConfiguration()
        
        // –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        currentLens = lens
        print("üì∑ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–æ –Ω–∞ –ª–∏–Ω–∑—É: \(lens.displayLabel)")
    }
    
    /// –ü–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç –º–µ–∂–¥—É —Ñ—Ä–æ–Ω—Ç–∞–ª—å–Ω–æ–π –∏ –∑–∞–¥–Ω–µ–π –∫–∞–º–µ—Ä–æ–π
    func switchCamera() async throws {
        let newPosition: AVCaptureDevice.Position = currentCamera?.position == .back ? .front : .back
        
        // –î–ª—è —Ñ—Ä–æ–Ω—Ç–∞–ª—å–Ω–æ–π –∫–∞–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ wide
        let targetLens: LensPreset = newPosition == .front ? .wide : currentLens
        
        guard let newCamera = getDevice(for: targetLens, position: newPosition) else {
            throw CameraError.noCameraAvailable
        }
        
        let newInput = try AVCaptureDeviceInput(device: newCamera)
        
        captureSession.beginConfiguration()
        
        if let oldInput = videoDeviceInput {
            captureSession.removeInput(oldInput)
        }
        
        guard captureSession.canAddInput(newInput) else {
            captureSession.commitConfiguration()
            throw CameraError.noCameraAvailable
        }
        
        captureSession.addInput(newInput)
        videoDeviceInput = newInput
        currentCamera = newCamera
        
        configurePhotoOutput(for: newCamera)
        captureSession.commitConfiguration()
        
        // –û–±–Ω–æ–≤–ª—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ª–∏–Ω–∑—ã –¥–ª—è –Ω–æ–≤–æ–π –ø–æ–∑–∏—Ü–∏–∏
        if newPosition == .front {
            availableLenses = [.wide]
        } else {
            detectAvailableLenses()
        }
        currentLens = targetLens
    }

    // MARK: - Photo Capture
    
    func capturePhoto(completion: @escaping (PhotoCapture?) -> Void) {
        let settings = AVCapturePhotoSettings()
        settings.flashMode = .auto
        settings.photoQualityPrioritization = .quality
        
        // –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ (48MP –Ω–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö)
        if #available(iOS 16.0, *) {
            if let camera = currentCamera,
               let maxDimension = camera.activeFormat.supportedMaxPhotoDimensions.max(by: {
                   $0.width * $0.height < $1.width * $1.height
               }) {
                settings.maxPhotoDimensions = maxDimension
            }
        } else {
            settings.isHighResolutionPhotoEnabled = true
        }
        
        let delegate = PhotoCaptureDelegate(completion: completion)
        self.photoCaptureDelegate = delegate
        
        photoOutput.capturePhoto(with: settings, delegate: delegate)
    }
}

// MARK: - Photo Capture Delegate

private class PhotoCaptureDelegate: NSObject, AVCapturePhotoCaptureDelegate {
    private let completion: (PhotoCapture?) -> Void
    
    init(completion: @escaping (PhotoCapture?) -> Void) {
        self.completion = completion
    }
    
    func photoOutput(_ output: AVCapturePhotoOutput, didFinishProcessingPhoto photo: AVCapturePhoto, error: Error?) {
        if let error = error {
            print("‚ùå Capture error: \(error)")
            completion(nil)
            return
        }
        
        guard let data = photo.fileDataRepresentation() else {
            print("‚ùå No data representation")
            completion(nil)
            return
        }
        
        let image = UIImage(data: data)
        print("‚úÖ –§–æ—Ç–æ –∑–∞—Ö–≤–∞—á–µ–Ω–æ: \(image?.size.width ?? 0) x \(image?.size.height ?? 0)")
        completion(PhotoCapture(processedImage: image, processedData: data, rawData: nil))
    }
}
